{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the data and create dictionaries of the bitcoin ticker values\n",
    "filename = 'Coin Prices.csv'\n",
    "coin_prices_df = pd.read_csv(filename)\n",
    "coin_dictionary = pd.Series(coin_prices_df.Ticker.values, index=coin_prices_df.index.values).to_dict()\n",
    "\n",
    "filename = 'Coin Sentiment.csv'\n",
    "sentiment_df = pd.read_csv(filename)\n",
    "sentiment_dictionary = pd.Series(sentiment_df.Ticker.values, index=sentiment_df.index.values).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process data into array of values and exclude specific coins\n",
    "#List of coin tickers to ignore because of incomplete data sets:\n",
    "coins_to_remove = ['BQX', 'IOTA', 'LLT', 'YOYO', 'VIBE']\n",
    "coin_dictionary = {k: v for k, v in coin_dictionary.items() if not v in coins_to_remove}\n",
    "\n",
    "price_data_list = []\n",
    "sentiment_data_list = []\n",
    "for coin in coin_dictionary.values():\n",
    "    coin_price_list = coin_prices_df[coin_prices_df['Ticker'] == coin].values[0,5:]\n",
    "    sentiment_list = sentiment_df[coin_prices_df['Ticker'] == coin].values[0,5:]\n",
    "    price_data_list.append(coin_price_list)\n",
    "    sentiment_data_list.append(sentiment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1287)\n"
     ]
    }
   ],
   "source": [
    "#Only use the Coin Price Information At This Time\n",
    "#Length of time series\n",
    "L = len(price_data_list[0])\n",
    "#Number of coins\n",
    "N = len(coin_dictionary)\n",
    "\n",
    "x = np.empty((N, L), 'float64')\n",
    "x2 = np.empty((N, L), 'float64')\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put all the data into the numpy array\n",
    "for i in range(len(price_data_list)):\n",
    "    x[i,:] = price_data_list[i]\n",
    "    x2[i,:] = sentiment_data_list[i]\n",
    "\n",
    "#Normalize the data for training\n",
    "normalized_x =  x/np.linalg.norm(x, ord=np.inf, axis=1, keepdims=True)\n",
    "\n",
    "#Do not normalize x2 as many of the values are zeroes\n",
    "normalized_x2 = x2\n",
    "\n",
    "torch.save(x, open('x.pt', 'wb'))\n",
    "torch.save(x2, open('x2.pt', 'wb'))\n",
    "\n",
    "torch.save(normalized_x, open('coin_train.pt', 'wb'))\n",
    "torch.save(normalized_x2, open('sentiment_train.pt', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "class Sequence(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_nodes):\n",
    "        super(Sequence, self).__init__()\n",
    "        \n",
    "        self.input_nodes = input_nodes\n",
    "        self.output_nodes = 200\n",
    "        \n",
    "        self.number_of_nodes_1 = 50\n",
    "        self.number_of_nodes_2 = 25\n",
    "        #self.number_of_nodes_3 = \n",
    "        \n",
    "        self.lstm1 = nn.LSTMCell(self.input_nodes, self.number_of_nodes_1)\n",
    "        self.lstm2 = nn.LSTMCell(self.number_of_nodes_1, self.number_of_nodes_2)\n",
    "        #self.lstm3 = nn.LSTMCell(self.number_of_nodes_2, self.number_of_nodes_3)\n",
    "        self.linear = nn.Linear(self.number_of_nodes_2, self.output_nodes)\n",
    "\n",
    "    def forward(self, input, future = 0):\n",
    "        outputs = []\n",
    "        \n",
    "        h_t = torch.zeros(input.size(0), self.number_of_nodes_1, dtype=torch.double)\n",
    "        c_t = torch.zeros(input.size(0), self.number_of_nodes_1, dtype=torch.double)\n",
    "        h_t2 = torch.zeros(input.size(0), self.number_of_nodes_2, dtype=torch.double)\n",
    "        c_t2 = torch.zeros(input.size(0), self.number_of_nodes_2, dtype=torch.double)\n",
    "        #h_t3 = torch.zeros(input.size(0), self.number_of_nodes_3, dtype=torch.double)\n",
    "        #c_t3 = torch.zeros(input.size(0), self.number_of_nodes_3, dtype=torch.double)\n",
    "\n",
    "        #Break the data up into chunks where we can determine the number of input nodes\n",
    "        number_of_chunks = input.shape[1] - (self.input_nodes - 2*100)\n",
    "        \n",
    "        for i in range(number_of_chunks//(2*100)):\n",
    "            \n",
    "            input_t = input[:,2*100*i:2*100*i+self.input_nodes]\n",
    "            \n",
    "            h_t, c_t = self.lstm1(input_t, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            #h_t3, c_t3 = self.lstm3(h_t2, (h_t3, c_t3))\n",
    "            output = self.linear(h_t2)\n",
    "            outputs += [output]\n",
    "                  \n",
    "        for i in range(future):# if we should predict the future\n",
    "            #Output is 200 points \n",
    "            output = outputs[-self.input_nodes//(2*100):]\n",
    "            output = torch.stack(output, 2).reshape((1,self.input_nodes))\n",
    "            \n",
    "            h_t, c_t = self.lstm1(output, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            #h_t3, c_t3 = self.lstm3(h_t2, (h_t3, c_t3))\n",
    "            output = self.linear(h_t2)\n",
    "            outputs += [output]\n",
    "            \n",
    "        outputs = torch.stack(outputs, 1).reshape((1,self.output_nodes*len(outputs)))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('coin_train.pt')\n",
    "sentiment = torch.load('sentiment_train.pt')\n",
    "x = torch.load('x.pt')\n",
    "x_2 = torch.load('x2.pt')\n",
    "\n",
    "dim1, dim2 = data.shape\n",
    "\n",
    "#Reshape the data so that it is a single row of values\n",
    "data = data.reshape((1,dim1*dim2))\n",
    "sentiment = sentiment.reshape((1,dim1*dim2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zip together the data and sentiment \n",
    "\n",
    "joined = np.empty((data.shape[0], data.shape[1]*2), 'float64')\n",
    "\n",
    "for i in range(x.shape[1]):\n",
    "    joined[:,dim1*i:dim1*i+dim1] = data[:,dim1*i:dim1*i+dim1]\n",
    "    joined[:,dim1*i+dim1:dim1*i+2*dim1] = sentiment[:,dim1*i:dim1*i+dim1]\n",
    "\n",
    "#Number of input points\n",
    "num_inputs = 100\n",
    "num_vars = 2\n",
    "input_nodes = 5 * num_vars * num_inputs\n",
    "\n",
    "input = torch.from_numpy(joined[:, :-num_vars*num_inputs])\n",
    "test_input = input\n",
    "target = torch.from_numpy(joined[:, input_nodes:])\n",
    "test_target = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128700)\n",
      "torch.Size([1, 257200]) torch.Size([1, 256400]) torch.Size([1, 257200]) torch.Size([1, 256400])\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(input.shape, target.shape, test_input.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    #Output predicts the single next value\n",
    "    out = seq(input)\n",
    "    #print(\"in closure:\", out.shape, target.shape)\n",
    "    \n",
    "    loss = criterion(out, target)\n",
    "    print('loss:', loss.item())\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "def draw(yi, color):\n",
    "    plt.plot(np.arange(normalized_x.shape[1]), yi[:normalized_x.shape[1]], color, linewidth = 2.0)\n",
    "    plt.plot(np.arange(normalized_x.shape[1], normalized_x.shape[1] + future - 5), yi[normalized_x.shape[1]:], color + ':', linewidth = 2.0)\n",
    "\n",
    "def iteration_plot(y):\n",
    "    # draw the result\n",
    "    plt.figure(figsize=(30,10))\n",
    "    plt.title('Predict future values for time sequences\\n(Dashlines are predicted values)', fontsize=30)\n",
    "    plt.xlabel('x', fontsize=20)\n",
    "    plt.ylabel('y', fontsize=20)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    draw(y[0], 'r')\n",
    "    draw(y[1], 'g')\n",
    "    draw(y[2], 'b')\n",
    "    plt.savefig('output_connected/predict_iteration_%d.pdf'%i)\n",
    "    plt.close()\n",
    "\n",
    "def regenerate_price(y):\n",
    "    new_y = np.empty((100, y.shape[1]//200), 'float64')\n",
    "    for i in range(y.shape[1]//200):\n",
    "        new_y[:,i] = y[:,i*200:i*200+100]\n",
    "    return new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:  0\n",
      "loss: 0.1848626061503831\n",
      "loss: 0.18475296010890044\n",
      "loss: 0.1604139417137515\n",
      "loss: 0.15054078919648675\n",
      "loss: 0.10515249709256097\n",
      "loss: 0.06471459554730906\n",
      "loss: 0.059696563065083044\n",
      "loss: 0.040053560413436266\n",
      "loss: 0.03158861991275033\n",
      "loss: 0.028523341136865006\n",
      "loss: 0.026098656588490705\n",
      "loss: 0.023913662210051128\n",
      "loss: 0.022534018191241924\n",
      "loss: 0.021596925941314127\n",
      "loss: 0.020720892740674127\n",
      "loss: 0.020323575318530466\n",
      "loss: 0.020002362501938174\n",
      "loss: 0.019682563617390264\n",
      "loss: 0.019477144230362762\n",
      "loss: 0.01921179746748161\n",
      "test loss: 0.01897502540459723\n",
      "STEP:  1\n",
      "loss: 0.01897502540459723\n",
      "loss: 0.01877913359002115\n",
      "loss: 0.01858964398151032\n",
      "loss: 0.01839650741146267\n",
      "loss: 0.01822071189569183\n",
      "loss: 0.017977049428411367\n",
      "loss: 0.017691914148906456\n",
      "loss: 0.017180985410471684\n",
      "loss: 0.01652589401388437\n",
      "loss: 0.016029906430526382\n",
      "loss: 0.01551371395551794\n",
      "loss: 0.015073770784657171\n",
      "loss: 0.014755638996501926\n",
      "loss: 0.014465509316073391\n",
      "loss: 0.014137036343025027\n",
      "loss: 0.013786129904108857\n",
      "loss: 0.013376981408579446\n",
      "loss: 0.01304526590578174\n",
      "loss: 0.01289792673380971\n",
      "loss: 0.012787177510392248\n",
      "test loss: 0.012545047809557255\n",
      "STEP:  2\n",
      "loss: 0.012545047809557255\n",
      "loss: 0.012316844168609606\n",
      "loss: 0.011999117490396699\n",
      "loss: 0.01171071058116582\n",
      "loss: 0.011499332879998148\n",
      "loss: 0.011312189275146808\n",
      "loss: 0.011148923219928464\n",
      "loss: 0.010977187304296393\n",
      "loss: 0.01080794738039873\n",
      "loss: 0.010591611513341806\n",
      "loss: 0.010362207628553033\n",
      "loss: 0.010194475549987859\n",
      "loss: 0.010107001179729189\n",
      "loss: 0.010024662394391416\n",
      "loss: 0.009938788438028454\n",
      "loss: 0.009838927620584711\n",
      "loss: 0.009730021146678364\n",
      "loss: 0.009613206396083481\n",
      "loss: 0.009495313686649168\n",
      "loss: 0.009362164482093916\n",
      "test loss: 0.009235559937155937\n",
      "STEP:  3\n",
      "loss: 0.009235559937155937\n",
      "loss: 0.009073171643583679\n",
      "loss: 0.008906306135455337\n",
      "loss: 0.008775047388512923\n",
      "loss: 0.008705213028646023\n",
      "loss: 0.008646514831890101\n",
      "loss: 0.008598635281357306\n",
      "loss: 0.008557471703355057\n",
      "loss: 0.008515425332450722\n",
      "loss: 0.008472409902955284\n",
      "loss: 0.008429283742673632\n",
      "loss: 0.00838700667476888\n",
      "loss: 0.00834418024608742\n",
      "loss: 0.008297885499231996\n",
      "loss: 0.008247991512313615\n",
      "loss: 0.008192751929894285\n",
      "loss: 0.008134548137295647\n",
      "loss: 0.008072961807429358\n",
      "loss: 0.008014930614877395\n",
      "loss: 0.007957642374223644\n",
      "test loss: 0.007899425034653067\n",
      "STEP:  4\n",
      "loss: 0.007899425034653067\n",
      "loss: 0.007835900123159566\n",
      "loss: 0.007770153122445335\n",
      "loss: 0.007712224521852277\n",
      "loss: 0.007653385265820044\n",
      "loss: 0.007592125931991996\n",
      "loss: 0.007531193675112798\n",
      "loss: 0.0074675265067127095\n",
      "loss: 0.007401020294332825\n",
      "loss: 0.007317218724641758\n",
      "loss: 0.00722827406377776\n",
      "loss: 0.007174939169177224\n",
      "loss: 0.0071397395248246525\n",
      "loss: 0.007078695151763507\n",
      "loss: 0.007007769300821334\n",
      "loss: 0.006918143872061188\n",
      "loss: 0.006857032683941874\n",
      "loss: 0.006790595832298434\n",
      "loss: 0.006722823127694615\n",
      "loss: 0.006653793955125209\n",
      "test loss: 0.00659035523645619\n",
      "STEP:  5\n",
      "loss: 0.00659035523645619\n",
      "loss: 0.006525354729093917\n",
      "loss: 0.0064669900839028\n",
      "loss: 0.006409852715622372\n",
      "loss: 0.006352354830238401\n",
      "loss: 0.006285840327410289\n",
      "loss: 0.006214023539650713\n",
      "loss: 0.0061489022026656615\n",
      "loss: 0.006093107026741293\n",
      "loss: 0.006042443844523035\n",
      "loss: 0.005995538354520976\n",
      "loss: 0.005947614369230737\n",
      "loss: 0.005896853910036992\n",
      "loss: 0.005839077215321485\n",
      "loss: 0.005778046802343765\n",
      "loss: 0.005718917101227079\n",
      "loss: 0.005669147183012586\n",
      "loss: 0.005627195770516324\n",
      "loss: 0.005586137130697056\n",
      "loss: 0.005540039122103926\n",
      "test loss: 0.005496929527004929\n",
      "STEP:  6\n",
      "loss: 0.005496929527004929\n",
      "loss: 0.005456262248271686\n",
      "loss: 0.005416364015459991\n",
      "loss: 0.005386254493632713\n",
      "loss: 0.005357546743717288\n",
      "loss: 0.005333976738503726\n",
      "loss: 0.00531716725483789\n",
      "loss: 0.005295492449255868\n",
      "loss: 0.0052666885285339825\n",
      "loss: 0.005225538232222551\n",
      "loss: 0.005179135892091795\n",
      "loss: 0.005135196698761099\n",
      "loss: 0.00509612605170915\n",
      "loss: 0.005056413627645556\n",
      "loss: 0.005021220042195504\n",
      "loss: 0.004982403379065159\n",
      "loss: 0.004946732495002389\n",
      "loss: 0.004914065640012886\n",
      "loss: 0.004892170497269768\n",
      "loss: 0.004872317050524698\n",
      "test loss: 0.0048552757231097214\n",
      "STEP:  7\n",
      "loss: 0.0048552757231097214\n",
      "loss: 0.004839266803624023\n",
      "loss: 0.004822125535423596\n",
      "loss: 0.004801820897642488\n",
      "loss: 0.004778799714575829\n",
      "loss: 0.004754905467584392\n",
      "loss: 0.004733243873770098\n",
      "loss: 0.004717005347796191\n",
      "loss: 0.004699525666572691\n",
      "loss: 0.004679660019158342\n",
      "loss: 0.004656684545248595\n",
      "loss: 0.004631993870902292\n",
      "loss: 0.0046084288944910085\n",
      "loss: 0.004585132353686416\n",
      "loss: 0.004565908656255543\n",
      "loss: 0.004541131736759149\n",
      "loss: 0.004513097753485117\n",
      "loss: 0.004479096068534345\n",
      "loss: 0.004436851259951832\n",
      "loss: 0.004403695066054464\n",
      "test loss: 0.004372501386999764\n",
      "STEP:  8\n",
      "loss: 0.004372501386999764\n",
      "loss: 0.004339993185317984\n",
      "loss: 0.00431522807727866\n",
      "loss: 0.004295698761569458\n",
      "loss: 0.004279632196243032\n",
      "loss: 0.004264271370759531\n",
      "loss: 0.00424867593726277\n",
      "loss: 0.004234075092466192\n",
      "loss: 0.004220304056714362\n",
      "loss: 0.004207330973932804\n",
      "loss: 0.004193888784278813\n",
      "loss: 0.004179061405608095\n",
      "loss: 0.004163432934543631\n",
      "loss: 0.004147035779898033\n",
      "loss: 0.004130901713802326\n",
      "loss: 0.004117590564354574\n",
      "loss: 0.004106278832206682\n",
      "loss: 0.004095101365694693\n",
      "loss: 0.004083961198387937\n",
      "loss: 0.004074097481802131\n",
      "test loss: 0.004065251088271469\n",
      "STEP:  9\n",
      "loss: 0.004065251088271469\n",
      "loss: 0.004056608408641737\n",
      "loss: 0.004046402601542246\n",
      "loss: 0.004032938321493264\n",
      "loss: 0.0040183307985745854\n",
      "loss: 0.004003137314834991\n",
      "loss: 0.003983492466135619\n",
      "loss: 0.003962524918137284\n",
      "loss: 0.003942254459689033\n",
      "loss: 0.003923534609396453\n",
      "loss: 0.0039085783630316605\n",
      "loss: 0.00389582645324196\n",
      "loss: 0.003884220371892543\n",
      "loss: 0.0038739824735450133\n",
      "loss: 0.0038644410850679333\n",
      "loss: 0.0038552208453888773\n",
      "loss: 0.0038458826264867966\n",
      "loss: 0.0038366663890689575\n",
      "loss: 0.0038264608515639347\n",
      "loss: 0.0038147821379937025\n",
      "test loss: 0.0038027473461581876\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "\n",
    "# build the model\n",
    "seq = Sequence(input_nodes)\n",
    "seq.double()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# use LBFGS as optimizer since we can load the whole data to train\n",
    "optimizer = optim.LBFGS(seq.parameters(), lr=0.25)\n",
    "\n",
    "#begin to train\n",
    "for i in range(iterations):\n",
    "    \n",
    "    print('STEP: ', i)\n",
    "    optimizer.step(closure)\n",
    "    \n",
    "    # begin to predict, no need to track gradient here\n",
    "    with torch.no_grad():\n",
    "        future = 1000\n",
    "        pred = seq(test_input, future=future)\n",
    "        loss = criterion(pred[:, :-(200*future)], test_target)\n",
    "        print('test loss:', loss.item())\n",
    "        y = pred.detach().numpy()\n",
    "        y = regenerate_price(y)\n",
    "    \n",
    "    # draw the result\n",
    "    iteration_plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bitcoin.pickle', 'wb') as handle:\n",
    "    pickle.dump(seq, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('bitcoin.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Predictions for all coins\n",
    "with torch.no_grad():\n",
    "    future = 1000\n",
    "    pred = seq(input, future=future)\n",
    "    loss = criterion(pred[:, :-(200*future)], target)\n",
    "    y = pred.detach().numpy()\n",
    "    #Convert the output back into prices and corresponding to the coins\n",
    "    y = regenerate_price(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the predictions back to the coin values\n",
    "pred_transformed = y * np.linalg.norm(x, ord=np.inf, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the values for specific time periods to create a nice tabular output\n",
    "last_actuals = pred_transformed[:,x.shape[1]]\n",
    "predicted_24_hrs = pred_transformed[:,x.shape[1] + 24]\n",
    "predicted_48_hrs = pred_transformed[:,x.shape[1] + 48]\n",
    "predicted_168_hrs = pred_transformed[:,x.shape[1] + 168]\n",
    "predicted_24_percent = predicted_24_hrs / last_actuals\n",
    "predicted_48_percent = predicted_48_hrs / last_actuals\n",
    "predicted_168_percent = predicted_168_hrs / last_actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a summary dataframe that shows the information\n",
    "result_df = pd.DataFrame()\n",
    "result_df['ticker'] = coin_dictionary.values()\n",
    "result_df['Current_Val'] = last_actuals\n",
    "result_df['24_hr_pred'] = predicted_24_hrs\n",
    "result_df['48_hr_pred'] = predicted_48_hrs\n",
    "result_df['168_hr_pred'] = predicted_168_hrs\n",
    "result_df['24_hr_percent'] = predicted_24_percent\n",
    "result_df['48_hr_percent'] = predicted_48_percent\n",
    "result_df['168_hr_percent'] = predicted_168_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_figures(preds, df, future=0, label=\"\"):\n",
    "    #Create a figure for each ticker\n",
    "    for i, ticker in df['ticker'].iteritems():\n",
    "        # draw the result\n",
    "        plt.figure(figsize=(30,10))\n",
    "        plt.title('Predict future values for time sequences\\n(Dashlines are predicted values)', fontsize=30)\n",
    "        plt.xticks(fontsize=20)\n",
    "        plt.yticks(fontsize=20)\n",
    "        ticker_plot = preds[i]\n",
    "        plt.plot(np.arange(len(ticker_plot)-future), ticker_plot[:len(ticker_plot)-future], 'r',\n",
    "                 linewidth = 2.0,label=ticker)\n",
    "        plt.plot(np.arange(len(ticker_plot)-1000, len(ticker_plot)), ticker_plot[len(ticker_plot)-future:],\n",
    "                 'r:', linewidth = 2.0)\n",
    "        plt.savefig('output_connected/' + label + ticker + '.pdf')\n",
    "        plt.close()\n",
    "\n",
    "def draw_all_figures(preds, df, future=0, label=\"\"):\n",
    "    #Set up the initial plot\n",
    "    fig = plt.figure(figsize=(30,10))\n",
    "    plt.title('Predict future values for all coins\\n(Dashlines are predicted values)', fontsize=30)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    ax = fig.add_subplot(111)\n",
    "    cycler = ax._get_lines.prop_cycler\n",
    "    \n",
    "    for i, ticker in df['ticker'].iteritems():\n",
    "        # draw a line for each prediction\n",
    "        ticker_plot = preds[i]\n",
    "        current_color = next(cycler)\n",
    "        plt.plot(np.arange(len(ticker_plot)-future), ticker_plot[:len(ticker_plot)-future], current_color['color'], \n",
    "                 linewidth = 2.0, label=ticker)\n",
    "        plt.plot(np.arange(len(ticker_plot)-1000, len(ticker_plot)), ticker_plot[len(ticker_plot)-future:], \n",
    "                 current_color['color'], linestyle = '--', linewidth = 2.0)\n",
    "    \n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig('output_connected/All_' + label + '.pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bisedab\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5eb\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >ticker</th> \n",
       "        <th class=\"col_heading level0 col1\" >Current_Val</th> \n",
       "        <th class=\"col_heading level0 col2\" >24_hr_pred</th> \n",
       "        <th class=\"col_heading level0 col3\" >48_hr_pred</th> \n",
       "        <th class=\"col_heading level0 col4\" >168_hr_pred</th> \n",
       "        <th class=\"col_heading level0 col5\" >24_hr_percent</th> \n",
       "        <th class=\"col_heading level0 col6\" >48_hr_percent</th> \n",
       "        <th class=\"col_heading level0 col7\" >168_hr_percent</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5eblevel0_row0\" class=\"row_heading level0 row0\" >90</th> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow0_col0\" class=\"data row0 col0\" >TRX</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow0_col1\" class=\"data row0 col1\" >-1.63618e-05</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow0_col2\" class=\"data row0 col2\" >-0.00326283</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow0_col3\" class=\"data row0 col3\" >-0.00330543</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow0_col4\" class=\"data row0 col4\" >-0.00330492</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow0_col5\" class=\"data row0 col5\" >19941.82%</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow0_col6\" class=\"data row0 col6\" >20202.13%</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow0_col7\" class=\"data row0 col7\" >20199.03%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5eblevel0_row1\" class=\"row_heading level0 row1\" >29</th> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow1_col0\" class=\"data row1 col0\" >DGD</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow1_col1\" class=\"data row1 col1\" >0.48359</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow1_col2\" class=\"data row1 col2\" >51.2364</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow1_col3\" class=\"data row1 col3\" >55.7336</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow1_col4\" class=\"data row1 col4\" >55.7798</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow1_col5\" class=\"data row1 col5\" >10595.01%</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow1_col6\" class=\"data row1 col6\" >11524.97%</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow1_col7\" class=\"data row1 col7\" >11534.52%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5eblevel0_row2\" class=\"row_heading level0 row2\" >16</th> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow2_col0\" class=\"data row2 col0\" >BTG</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow2_col1\" class=\"data row2 col1\" >0.0387133</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow2_col2\" class=\"data row2 col2\" >3.46638</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow2_col3\" class=\"data row2 col3\" >3.60835</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow2_col4\" class=\"data row2 col4\" >3.60843</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow2_col5\" class=\"data row2 col5\" >8953.97%</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow2_col6\" class=\"data row2 col6\" >9320.71%</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow2_col7\" class=\"data row2 col7\" >9320.91%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5eblevel0_row3\" class=\"row_heading level0 row3\" >38</th> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow3_col0\" class=\"data row3 col0\" >LEND</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow3_col1\" class=\"data row3 col1\" >8.22743e-05</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow3_col2\" class=\"data row3 col2\" >0.0073455</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow3_col3\" class=\"data row3 col3\" >0.00751572</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow3_col4\" class=\"data row3 col4\" >0.00751626</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow3_col5\" class=\"data row3 col5\" >8928.06%</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow3_col6\" class=\"data row3 col6\" >9134.95%</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow3_col7\" class=\"data row3 col7\" >9135.61%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5eblevel0_row4\" class=\"row_heading level0 row4\" >88</th> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow4_col0\" class=\"data row4 col0\" >TNB</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow4_col1\" class=\"data row4 col1\" >-3.97974e-05</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow4_col2\" class=\"data row4 col2\" >-0.00346086</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow4_col3\" class=\"data row4 col3\" >-0.00377788</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow4_col4\" class=\"data row4 col4\" >-0.00378418</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow4_col5\" class=\"data row4 col5\" >8696.22%</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow4_col6\" class=\"data row4 col6\" >9492.79%</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow4_col7\" class=\"data row4 col7\" >9508.63%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5eblevel0_row5\" class=\"row_heading level0 row5\" >21</th> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow5_col0\" class=\"data row5 col0\" >ADA</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow5_col1\" class=\"data row5 col1\" >0.000412667</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow5_col2\" class=\"data row5 col2\" >0.0294204</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow5_col3\" class=\"data row5 col3\" >0.0298955</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow5_col4\" class=\"data row5 col4\" >0.0298864</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow5_col5\" class=\"data row5 col5\" >7129.33%</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow5_col6\" class=\"data row5 col6\" >7244.46%</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow5_col7\" class=\"data row5 col7\" >7242.25%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5eblevel0_row6\" class=\"row_heading level0 row6\" >22</th> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow6_col0\" class=\"data row6 col0\" >CTR</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow6_col1\" class=\"data row6 col1\" >8.15889e-05</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow6_col2\" class=\"data row6 col2\" >0.00492676</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow6_col3\" class=\"data row6 col3\" >0.00361645</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow6_col4\" class=\"data row6 col4\" >0.00361433</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow6_col5\" class=\"data row6 col5\" >6038.51%</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow6_col6\" class=\"data row6 col6\" >4432.52%</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow6_col7\" class=\"data row6 col7\" >4429.92%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5eblevel0_row7\" class=\"row_heading level0 row7\" >12</th> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow7_col0\" class=\"data row7 col0\" >BNB</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow7_col1\" class=\"data row7 col1\" >0.0070019</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow7_col2\" class=\"data row7 col2\" >0.42066</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow7_col3\" class=\"data row7 col3\" >0.421614</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow7_col4\" class=\"data row7 col4\" >0.421362</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow7_col5\" class=\"data row7 col5\" >6007.79%</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow7_col6\" class=\"data row7 col6\" >6021.41%</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow7_col7\" class=\"data row7 col7\" >6017.82%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5eblevel0_row8\" class=\"row_heading level0 row8\" >5</th> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow8_col0\" class=\"data row8 col0\" >AST</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow8_col1\" class=\"data row8 col1\" >0.000914164</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow8_col2\" class=\"data row8 col2\" >0.0445991</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow8_col3\" class=\"data row8 col3\" >0.0499837</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow8_col4\" class=\"data row8 col4\" >0.0500303</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow8_col5\" class=\"data row8 col5\" >4878.67%</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow8_col6\" class=\"data row8 col6\" >5467.69%</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow8_col7\" class=\"data row8 col7\" >5472.79%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5eblevel0_row9\" class=\"row_heading level0 row9\" >84</th> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow9_col0\" class=\"data row9 col0\" >SUB</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow9_col1\" class=\"data row9 col1\" >-0.000636895</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow9_col2\" class=\"data row9 col2\" >-0.0259929</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow9_col3\" class=\"data row9 col3\" >-0.0302451</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow9_col4\" class=\"data row9 col4\" >-0.0303165</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow9_col5\" class=\"data row9 col5\" >4081.19%</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow9_col6\" class=\"data row9 col6\" >4748.83%</td> \n",
       "        <td id=\"T_ea58d814_ed0a_11e8_b39b_80000b9bf5ebrow9_col7\" class=\"data row9 col7\" >4760.05%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c9cf080>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicted Top Performers\n",
    "top_df = result_df.sort_values('24_hr_percent', ascending=False)[0:10]\n",
    "#Create a graph of the top 10 performers\n",
    "draw_figures(pred_transformed, top_df, 1000, \"top_performers_\")\n",
    "draw_all_figures(pred_transformed, top_df, 1000, \"top_performers\")\n",
    "\n",
    "top_df.style.format({\n",
    "    '24_hr_percent': '{:.2%}'.format,\n",
    "    '48_hr_percent': '{:.2%}'.format,\n",
    "    '168_hr_percent': '{:.2%}'.format\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bisedab\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5eb\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >ticker</th> \n",
       "        <th class=\"col_heading level0 col1\" >Current_Val</th> \n",
       "        <th class=\"col_heading level0 col2\" >24_hr_pred</th> \n",
       "        <th class=\"col_heading level0 col3\" >48_hr_pred</th> \n",
       "        <th class=\"col_heading level0 col4\" >168_hr_pred</th> \n",
       "        <th class=\"col_heading level0 col5\" >24_hr_percent</th> \n",
       "        <th class=\"col_heading level0 col6\" >48_hr_percent</th> \n",
       "        <th class=\"col_heading level0 col7\" >168_hr_percent</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5eblevel0_row0\" class=\"row_heading level0 row0\" >45</th> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow0_col0\" class=\"data row0 col0\" >HSR</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow0_col1\" class=\"data row0 col1\" >-0.00218399</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow0_col2\" class=\"data row0 col2\" >0.75085</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow0_col3\" class=\"data row0 col3\" >0.823128</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow0_col4\" class=\"data row0 col4\" >0.823729</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow0_col5\" class=\"data row0 col5\" >-34379.75%</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow0_col6\" class=\"data row0 col6\" >-37689.18%</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow0_col7\" class=\"data row0 col7\" >-37716.72%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5eblevel0_row1\" class=\"row_heading level0 row1\" >18</th> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow1_col0\" class=\"data row1 col0\" >BCPT</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow1_col1\" class=\"data row1 col1\" >-0.00142543</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow1_col2\" class=\"data row1 col2\" >0.0850158</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow1_col3\" class=\"data row1 col3\" >0.0915019</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow1_col4\" class=\"data row1 col4\" >0.09158</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow1_col5\" class=\"data row1 col5\" >-5964.22%</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow1_col6\" class=\"data row1 col6\" >-6419.24%</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow1_col7\" class=\"data row1 col7\" >-6424.72%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5eblevel0_row2\" class=\"row_heading level0 row2\" >91</th> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow2_col0\" class=\"data row2 col0\" >VEN</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow2_col1\" class=\"data row2 col1\" >0.00938405</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow2_col2\" class=\"data row2 col2\" >-0.54222</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow2_col3\" class=\"data row2 col3\" >-0.581112</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow2_col4\" class=\"data row2 col4\" >-0.58159</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow2_col5\" class=\"data row2 col5\" >-5778.11%</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow2_col6\" class=\"data row2 col6\" >-6192.55%</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow2_col7\" class=\"data row2 col7\" >-6197.65%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5eblevel0_row3\" class=\"row_heading level0 row3\" >42</th> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow3_col0\" class=\"data row3 col0\" >GTO</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow3_col1\" class=\"data row3 col1\" >-0.00027555</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow3_col2\" class=\"data row3 col2\" >0.0132799</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow3_col3\" class=\"data row3 col3\" >0.0148108</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow3_col4\" class=\"data row3 col4\" >0.0148096</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow3_col5\" class=\"data row3 col5\" >-4819.41%</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow3_col6\" class=\"data row3 col6\" >-5375.01%</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow3_col7\" class=\"data row3 col7\" >-5374.56%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5eblevel0_row4\" class=\"row_heading level0 row4\" >66</th> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow4_col0\" class=\"data row4 col0\" >OAX</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow4_col1\" class=\"data row4 col1\" >0.00146127</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow4_col2\" class=\"data row4 col2\" >-0.0401686</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow4_col3\" class=\"data row4 col3\" >-0.0465541</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow4_col4\" class=\"data row4 col4\" >-0.0466266</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow4_col5\" class=\"data row4 col5\" >-2748.89%</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow4_col6\" class=\"data row4 col6\" >-3185.87%</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow4_col7\" class=\"data row4 col7\" >-3190.83%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5eblevel0_row5\" class=\"row_heading level0 row5\" >78</th> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow5_col0\" class=\"data row5 col0\" >SNGLS</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow5_col1\" class=\"data row5 col1\" >0.000380358</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow5_col2\" class=\"data row5 col2\" >-0.0102894</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow5_col3\" class=\"data row5 col3\" >-0.0112873</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow5_col4\" class=\"data row5 col4\" >-0.0112937</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow5_col5\" class=\"data row5 col5\" >-2705.18%</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow5_col6\" class=\"data row5 col6\" >-2967.55%</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow5_col7\" class=\"data row5 col7\" >-2969.22%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5eblevel0_row6\" class=\"row_heading level0 row6\" >61</th> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow6_col0\" class=\"data row6 col0\" >NEBL</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow6_col1\" class=\"data row6 col1\" >0.00662204</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow6_col2\" class=\"data row6 col2\" >-0.136798</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow6_col3\" class=\"data row6 col3\" >-0.104417</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow6_col4\" class=\"data row6 col4\" >-0.103832</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow6_col5\" class=\"data row6 col5\" >-2065.80%</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow6_col6\" class=\"data row6 col6\" >-1576.81%</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow6_col7\" class=\"data row6 col7\" >-1567.97%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5eblevel0_row7\" class=\"row_heading level0 row7\" >17</th> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow7_col0\" class=\"data row7 col0\" >BTS</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow7_col1\" class=\"data row7 col1\" >-0.000668049</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow7_col2\" class=\"data row7 col2\" >0.0121858</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow7_col3\" class=\"data row7 col3\" >0.013205</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow7_col4\" class=\"data row7 col4\" >0.0132213</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow7_col5\" class=\"data row7 col5\" >-1824.10%</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow7_col6\" class=\"data row7 col6\" >-1976.65%</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow7_col7\" class=\"data row7 col7\" >-1979.10%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5eblevel0_row8\" class=\"row_heading level0 row8\" >49</th> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow8_col0\" class=\"data row8 col0\" >KNC</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow8_col1\" class=\"data row8 col1\" >-0.116406</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow8_col2\" class=\"data row8 col2\" >1.36323</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow8_col3\" class=\"data row8 col3\" >1.51728</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow8_col4\" class=\"data row8 col4\" >1.5189</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow8_col5\" class=\"data row8 col5\" >-1171.10%</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow8_col6\" class=\"data row8 col6\" >-1303.44%</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow8_col7\" class=\"data row8 col7\" >-1304.84%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5eblevel0_row9\" class=\"row_heading level0 row9\" >63</th> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow9_col0\" class=\"data row9 col0\" >GAS</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow9_col1\" class=\"data row9 col1\" >-0.098062</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow9_col2\" class=\"data row9 col2\" >0.890122</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow9_col3\" class=\"data row9 col3\" >1.00665</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow9_col4\" class=\"data row9 col4\" >1.00886</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow9_col5\" class=\"data row9 col5\" >-907.71%</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow9_col6\" class=\"data row9 col6\" >-1026.54%</td> \n",
       "        <td id=\"T_f00db874_ed0a_11e8_b3bc_80000b9bf5ebrow9_col7\" class=\"data row9 col7\" >-1028.80%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a296438>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicted Worst Performers\n",
    "bottom_df = result_df.sort_values('24_hr_percent', ascending=True)[0:10]\n",
    "#Create a graph of the bottom 10 performers\n",
    "draw_figures(pred_transformed, bottom_df, 1000, \"bottom_performers_\")\n",
    "draw_all_figures(pred_transformed, bottom_df, 1000, \"bottom_performers\")\n",
    "\n",
    "bottom_df.style.format({\n",
    "    '24_hr_percent': '{:.2%}'.format,\n",
    "    '48_hr_percent': '{:.2%}'.format,\n",
    "    '168_hr_percent': '{:.2%}'.format\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x149d1ef0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xed90b00>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d0da208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
